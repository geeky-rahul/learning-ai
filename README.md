# AI Learning Journey

This repository contains all my learning materials and practice files related to AI, starting from Python basics and moving through essential libraries like NumPy, Pandas, Data Visualization, and Machine Learning projects.

---

## ğŸ“ Folders Overview

### ğŸ”¹ `python/` â€“ Python Basics
Core Python concepts with examples:
- Numbers, Strings, Lists, Tuples, Dictionaries
- Conditionals & Loops
- Itertools & Functions
- OOP, Decorators, Error Handling
- API Handling

### ğŸ”¹ `numpy/` â€“ NumPy Essentials
Notebooks covering:
- Array Basics & Operations
- Practice exercises
- Image storing using NumPy arrays

### ğŸ”¹ `pandas/` â€“ Data Analysis with Pandas
Comprehensive guides and notebooks:
- Series and DataFrames
- Handling Missing Data
- Merge, Join, GroupBy
- Pivot Tables and Operations
- Feature Extraction and Data Extraction
- Sample CSV datasets included

### ğŸ”¹ `data_visualization/` â€“ Data Visualization Techniques
Learning how to visualize data using:
- `matplotlib` basics
- Distribution, Categorical, Matrix, and Regression plots with `seaborn`
- Interactive plots using `plotly` and `cufflinks`
- Includes sample images and visual examples

### ğŸ”¹ `machine_learning/` â€“ Hands-on ML Projects
Beginner-friendly ML projects with datasets:
- **Heart Disease Prediction** â€“ with model building and evaluation
- **Insurance Cost Prediction** â€“ using regression techniques
- **Titanic Survival Prediction** â€“ with cross-validation techniques
- **Clustering Techniques** â€“ KMeans and DBSCAN
- **PCA Dimensionality Reduction** â€“ for improving model performance
- **Ensemble Learning** â€“ using Bagging and Boosting methods
- **Supervised Learning Examples** â€“ covering classification and regression tasks
- CSV datasets included for practice

### ğŸ”¹ `NLP/` â€“ Natural Language Processing
Introductory NLP projects using NLTK:
- **Emotion Detection** â€“ using `stopwords`, `word_tokenize`, and custom preprocessing
- `train.txt` dataset for training basic emotion classifier
- Text preprocessing, cleaning, and tokenization steps demonstrated

---

## ğŸš€ Stay tuned for more updates!
